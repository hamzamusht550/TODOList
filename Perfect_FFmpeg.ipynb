{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamzamusht550/TODOList/blob/main/Perfect_FFmpeg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "r2oHTNUEwdWB"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title Install Dependencies\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from google.colab import drive\n",
        "from google.colab import auth\n",
        "\n",
        "!apt-get install -y mediainfo ffmpeg mkvtoolnix aria2\n",
        "!pip install patool pymediainfo ffmpeg-python pyrogram tgcrypto nest_asyncio\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "auth.authenticate_user()\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtdKS9IfCze7",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title Get Mediainfo MKV\n",
        "\n",
        "MKV_INFO = \"/content/The.Roshans.S01.720p.NF.WEB-DL.AAC5.1.AV1-PrimeFix/E2 (1).mkv\" #@param {type: \"string\"}\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "\n",
        "# !ffmpeg -i {MKV_INFO}\n",
        "# !ffprobe -i \"{MKV_INFO}\" -show_streams\n",
        "!mediainfo \"{MKV_INFO}\" && mediainfo \"{MKV_INFO}\" > \"{MKV_INFO}\".txt\n",
        "!du -h \"{MKV_INFO}\"\n",
        "!du -BM \"{MKV_INFO}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ogYK0G0INKoR"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#@title FFmpeg\n",
        "\n",
        "FILES = \"/content/The.Roshans.S01.720p.NF.WEB-DL.AAC5.1.AV1-PrimeFix/E2.mkv\"  # @param {type: \"string\"}\n",
        "FFMPEG_OPTIONS = \"-map 0:v -map 0:a:m:language:hin -map 0:s? -c copy\"  #@param {type: \"string\"}\n",
        "Delete_Extracted_Data = False  #@param {type: \"boolean\"}\n",
        "#@markdown ***Start 00:00:00 / End 00:00:10***\n",
        "trim_start = \"\"  #@param {type: \"string\"}\n",
        "trim_end = \"\"  #@param {type: \"string\"}\n",
        "JUST_DOWNLOAD= False  #@param {type: \"boolean\"}\n",
        "JUST_EXTRACT= False  #@param {type: \"boolean\"}\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import subprocess\n",
        "import os\n",
        "import re\n",
        "import requests\n",
        "import patoolib\n",
        "from google.colab import drive\n",
        "from zipfile import ZipFile\n",
        "from pymediainfo import MediaInfo\n",
        "import mimetypes\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "clear_output()\n",
        "\n",
        "\n",
        "def strToList(listStr, separator=\",\"):\n",
        "    listStr = ' '.join(listStr.split()) # Remove extra spaces from String\n",
        "    myList = [_.strip() for _ in listStr.split(separator)]\n",
        "    myList = [_ for _ in myList if _ and _.strip()] # Remove empty items from list\n",
        "    showAllURLs = \"\\n\".join(f\"{i+1}. {ele}\" for i, ele in enumerate(myList))\n",
        "    print(showAllURLs)\n",
        "    return myList\n",
        "\n",
        "\n",
        "def printObj(obj):\n",
        "    objToStr = str(vars(obj))\n",
        "    print(objToStr)\n",
        "\n",
        "\n",
        "def getSize(input_file):\n",
        "    !du -h \"{input_file}\"\n",
        "    !du -BM \"{input_file}\"\n",
        "\n",
        "\n",
        "def copy(source, destination, isDeleteSource=0):\n",
        "    if isDeleteSource == 0:\n",
        "        !rsync -ah --progress \"{source}\" \"{destination}\"\n",
        "    if isDeleteSource == 1:\n",
        "        !rsync -ah --progress --remove-source-files \"{source}\" \"{destination}\"\n",
        "        print(f\"Source deleted: {source}\")\n",
        "    print(f\"Transfer Successfull:\\nSource => {source}\\nDestination => {destination}\")\n",
        "\n",
        "\n",
        "def deleteFile(input_file):\n",
        "    !rm \"{input_file}\"\n",
        "    print(f\"File Deleted: {input_file}\")\n",
        "\n",
        "\n",
        "def deleteFolder(input_folder):\n",
        "    !rm -rf \"{input_folder}\"\n",
        "    print(f\"Folder Deleted: {input_folder}\")\n",
        "\n",
        "\n",
        "def printMediaInfo(input_file):\n",
        "    \"\"\"Display media information.\"\"\"\n",
        "    !mediainfo \"{input_file}\"\n",
        "\n",
        "\n",
        "def extract_file_info(file_path):\n",
        "    # parent_dir_path = os.path.dirname(file_path)\n",
        "    # file_name = os.path.basename(file_path)\n",
        "    parent_dir_path, file_name = os.path.split(file_path)\n",
        "    _name, _ext = os.path.splitext(file_name)\n",
        "    return parent_dir_path,  file_name, _name, _ext[1:]\n",
        "\n",
        "def add_suffix_to_file(file_path, suffix=\"_Suffix\"):\n",
        "    parent_dir_path, file_name = os.path.split(file_path)\n",
        "    name, ext = os.path.splitext(file_name)\n",
        "    new_file_name = f\"{name}{suffix}{ext}\"\n",
        "    new_file_path = os.path.join(parent_dir_path, new_file_name)\n",
        "    return new_file_path\n",
        "\n",
        "def filter_existing_filepath(base_path):\n",
        "    directory, filename = os.path.split(base_path)\n",
        "    name, ext = os.path.splitext(filename)\n",
        "\n",
        "    counter = 1\n",
        "    new_path = base_path\n",
        "    while os.path.exists(new_path):\n",
        "        new_name = f\"{name} ({counter}){ext}\" if ext else f\"{name} ({counter})\"\n",
        "        new_path = os.path.join(directory, new_name)\n",
        "        counter += 1\n",
        "\n",
        "    return new_path\n",
        "\n",
        "\n",
        "def getFilesList(folder_path, relative=0):\n",
        "    all_files = []\n",
        "    for root, dirs, files in os.walk(folder_path):\n",
        "        for file in files:\n",
        "            full_path = os.path.join(root, file)\n",
        "            if relative == 1:\n",
        "                full_path = os.path.relpath(full_path, folder_path)\n",
        "            all_files.append(full_path)\n",
        "\n",
        "    all_files.sort()\n",
        "    return all_files\n",
        "\n",
        "\n",
        "def runCommand(cmd, showLog=0):\n",
        "    if showLog == 1:\n",
        "        # Print logs in real-time, if 2nd param is 1\n",
        "        print(f\"Running command: {cmd}\")\n",
        "        process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
        "        for line in iter(process.stdout.readline, b''):\n",
        "            print(line.decode(\"utf-8\"), end=\"\")\n",
        "\n",
        "        process.stdout.close()\n",
        "        process.wait()\n",
        "    else:\n",
        "        process = subprocess.run(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "    return process.returncode\n",
        "\n",
        "\n",
        "def getResponseFileName(url):\n",
        "    # Define the maximum filename length (commonly 255 characters)\n",
        "    MAX_FILENAME_LENGTH = 255\n",
        "\n",
        "    # Get the response from the URL\n",
        "    response = requests.get(url, stream=True)\n",
        "\n",
        "    # Extract the filename from the Content-Disposition header\n",
        "    filename = response.headers.get('content-disposition', '')\n",
        "    if 'filename=' in filename:\n",
        "        filename = filename.split(\"filename=\")[-1].strip('\"')\n",
        "    else:\n",
        "        return \"\"\n",
        "\n",
        "    # Define a regex pattern to match unsuitable characters for filenames\n",
        "    invalid_chars = r'[<>:\"/\\\\|?*\\']'\n",
        "\n",
        "    # Replace unsuitable characters with a hyphen\n",
        "    valid_filename = re.sub(invalid_chars, '-', filename)\n",
        "\n",
        "    # Truncate the filename if it exceeds the maximum length\n",
        "    if len(valid_filename) > MAX_FILENAME_LENGTH:\n",
        "        # Preserve the file extension if present\n",
        "        if '.' in valid_filename:\n",
        "            name, extension = valid_filename.rsplit('.', 1)\n",
        "            truncated_name = name[:MAX_FILENAME_LENGTH - len(extension) - 1]  # Reserve space for the dot\n",
        "            valid_filename = f\"{truncated_name}.{extension}\"\n",
        "        else:\n",
        "            valid_filename = valid_filename[:MAX_FILENAME_LENGTH]\n",
        "\n",
        "    return valid_filename\n",
        "\n",
        "\n",
        "def Aria2Downloader(url, output_file=''):\n",
        "    if not url.startswith(\"http\"):\n",
        "        print(f\"Invalid URL: {url}\")\n",
        "    _responseFileName = getResponseFileName(url)\n",
        "    if _responseFileName:\n",
        "        if not output_file:\n",
        "            output_file = _responseFileName\n",
        "        if os.path.exists(output_file):\n",
        "            print(f\"Download File Already Exists: {output_file}\")\n",
        "            return output_file\n",
        "        else:\n",
        "            \"\"\"Download a file using Aria2.\"\"\"\n",
        "            print(f\"Downloading file: {url}\")\n",
        "            command = f\"aria2c -x 16 -s 16 -o \\\"{output_file}\\\" {url}\"\n",
        "            status_code = runCommand(command, 1)\n",
        "            if status_code == 0:\n",
        "                print(f\"\\nDownload Successfull: {output_file}\\n\")\n",
        "                return output_file\n",
        "            else:\n",
        "                print(f\"Download Error Status code({status_code}): {url}\")\n",
        "    else:\n",
        "        print(f\"Download Error Response FileName: {url}\")\n",
        "    return url\n",
        "\n",
        "\n",
        "def useFFmpeg(input_file, output_file='', log=0):\n",
        "    if not output_file:\n",
        "        output_file = input_file\n",
        "    output_file = filter_existing_filepath(output_file)\n",
        "    global FFMPEG_OPTIONS\n",
        "    global trim_start\n",
        "    global trim_end\n",
        "    trim = \"\"\n",
        "    if trim_start:\n",
        "        trim = f\"-ss {trim_start} -to {trim_end}\"\n",
        "    if not FFMPEG_OPTIONS:\n",
        "        FFMPEG_OPTIONS = \"-map 0:v -map 0:a:m:language:hin -map 0:s? -c copy\"\n",
        "    command = f\"ffmpeg -i \\\"{input_file}\\\" {trim} {FFMPEG_OPTIONS} -y \\\"{output_file}\\\"\"\n",
        "    runCommand(command, log)\n",
        "    print(\"Original Size:\")\n",
        "    getSize(input_file)\n",
        "    print(\"NEW Size:\")\n",
        "    getSize(output_file)\n",
        "    return output_file\n",
        "\n",
        "def useFFmpegFolder(input_folder, log=0):\n",
        "    ffmpeg_folder = input_folder + \"_ffmpeg\"\n",
        "    if os.path.exists(ffmpeg_folder):\n",
        "        deleteFolder(ffmpeg_folder)\n",
        "    os.makedirs(ffmpeg_folder, exist_ok=True)\n",
        "\n",
        "    for i, file in enumerate(getFilesList(input_folder)):\n",
        "        if file.endswith(('.mkv', '.mp4', '.avi')):\n",
        "            output_file = os.path.join(ffmpeg_folder, os.path.split(file)[1])\n",
        "            print(f\"{i+1}: {file}\")\n",
        "            useFFmpeg(file, output_file, log)\n",
        "\n",
        "    print(f\"\\nFFmpeg Folder Operation Success: {ffmpeg_folder}\\n\")\n",
        "    return ffmpeg_folder\n",
        "\n",
        "\n",
        "def extractArchive(Archive_File, extracted_folder=''):\n",
        "    if not extracted_folder:\n",
        "        extracted_folder = os.path.splitext(Archive_File)[0]\n",
        "    if os.path.exists(extracted_folder):\n",
        "        deleteFolder(extracted_folder)\n",
        "    os.makedirs(extracted_folder, exist_ok=True)\n",
        "    print(f\"\\nExtracting archive to: {extracted_folder}\")\n",
        "    patoolib.extract_archive(Archive_File, outdir=extracted_folder)\n",
        "    print(f\"Extraction complete: {extracted_folder}\\n\")\n",
        "    return extracted_folder\n",
        "\n",
        "def createArchive(_folder, Archive_filepath):\n",
        "    if os.path.exists(Archive_filepath):\n",
        "        Archive_filepath = filter_existing_filepath(Archive_filepath)\n",
        "    print(\"Building ZIP ===> \", Archive_filepath)\n",
        "    patoolib.create_archive(Archive_filepath, getFilesList(_folder))\n",
        "    print(f\"Archived Success: {Archive_filepath}\")\n",
        "    return Archive_filepath\n",
        "\n",
        "def processArchive(Archive_File):\n",
        "    result_Archive = \"/content/drive/MyDrive/\" + os.path.split(Archive_File)[1]\n",
        "    extracted_folder = extractArchive(Archive_File)\n",
        "    if JUST_EXTRACT:\n",
        "     return\n",
        "    ffmpeg_folder = useFFmpegFolder(extracted_folder)\n",
        "    createArchive(ffmpeg_folder, result_Archive)\n",
        "    getSize(Archive_File)\n",
        "    getSize(result_Archive)\n",
        "    if Delete_Extracted_Data:\n",
        "        deleteFolder(extracted_folder)\n",
        "        deleteFolder(ffmpeg_folder)\n",
        "    return result_Archive\n",
        "\n",
        "\n",
        "# -------- Main Workflow --------\n",
        "\n",
        "def main(filesListStr):\n",
        "    drive_root = '/content/drive/MyDrive/'\n",
        "    Files_List = strToList(filesListStr)\n",
        "\n",
        "    for i, _File in enumerate(Files_List):\n",
        "        if _File.startswith('http'):\n",
        "            _File = Aria2Downloader(_File)\n",
        "            if JUST_DOWNLOAD:\n",
        "                return\n",
        "        if os.path.exists(_File):\n",
        "            if _File.endswith('.mkv'):\n",
        "                output_file = \"\"\n",
        "                if not _File.startswith(drive_root):\n",
        "                    output_file = os.path.join(drive_root, os.path.split(_File)[1])\n",
        "                useFFmpeg(_File, output_file, 1)\n",
        "            elif patoolib.is_archive(_File):\n",
        "                processArchive(_File)\n",
        "            elif os.path.isdir(_File):\n",
        "                useFFmpegFolder(_File, 1)\n",
        "            else:\n",
        "                print(\"File Exists but Unsupported File: \", _File)\n",
        "        else:\n",
        "            print(f\"Error FILES {i+1}: {_File}\")\n",
        "\n",
        "main(FILES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ngnONcUxrYo6"
      },
      "outputs": [],
      "source": [
        "#@title wget Downloader\n",
        "URL = \"https://mixologystreambot-6bb897237317.herokuapp.com/36695/60656c2c21894946bade447fea690315.mkv?hash=AgADlQ\"  #@param {type: \"string\"}\n",
        "\n",
        "!wget {URL} --no-verbose --show-progress -N"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "s-s3bMkIse2U"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title Save Public Google Drive Files\n",
        "\n",
        "from google.colab import drive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "from pydrive2.auth import GoogleAuth\n",
        "from pydrive2.drive import GoogleDrive\n",
        "\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "\n",
        "# Authenticate and initialize\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Get credentials\n",
        "credentials = GoogleCredentials.get_application_default()\n",
        "service = build('drive', 'v3', credentials=credentials)\n",
        "\n",
        "public_drive_urls = \"https://drive.google.com/file/d/13Qdkvg8uKGuZv2_8Z1kyUzCMSSlblEEb/view?usp=drivesdk\"  # @param {type: \"string\"}\n",
        "# https://drive.google.com/file/d/13Qdkvg8uKGuZv2_8Z1kyUzCMSSlblEEb/view?usp=drivesdk\n",
        "# https://drive.google.com/drive/folders/1NrBvFvL-Jro3VQBSQhHiOj4-oEEnCIUl\n",
        "# https://drive.google.com/drive/folders/1glEPV-ISGauk8_HXQ6dV6AfH1HJRsVc6?usp=sharing\n",
        "\n",
        "\n",
        "def strToList(listStr, separator=\",\"):\n",
        "    listStr = ' '.join(listStr.split()) # Remove extra spaces from String\n",
        "    myList = [_.strip() for _ in listStr.split(separator)]\n",
        "    myList = [_ for _ in myList if _ and _.strip()] # Remove empty items from list\n",
        "    showAllURLs = \"\\n\".join(f\"{i+1}. {ele}\" for i, ele in enumerate(myList))\n",
        "    print(showAllURLs)\n",
        "    return myList\n",
        "\n",
        "\n",
        "def cleanURL(url):\n",
        "    if not url:\n",
        "        return url\n",
        "    if \".\" in url:\n",
        "        if not url.lower().startswith(\"http\"):\n",
        "            url = \"http://\" + url\n",
        "\n",
        "    return url\n",
        "\n",
        "\n",
        "def extractPublicDriveID(url):\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    drive = GoogleDrive(gauth)\n",
        "    try:\n",
        "        # Check if the URL is a file or folder and extract the ID accordingly\n",
        "        file_id = \"\"\n",
        "        if \"file/d/\" in url:\n",
        "            file_id = url.split('/d/')[1].split('/')[0]\n",
        "        elif \"folders/\" in url:\n",
        "            file_id = url.split('folders/')[1].split('/')[0]\n",
        "        else:\n",
        "            return \"\"  # Invalid URL format\n",
        "\n",
        "        if \"?usp=sharing\" in file_id:\n",
        "            file_id = file_id.replace(\"?usp=sharing\",\"\")\n",
        "\n",
        "        # Create a file object and load metadata using the extracted ID\n",
        "        file = drive.CreateFile({'id': file_id})\n",
        "        file.FetchMetadata()  # Fetch metadata to verify ID and access permissions\n",
        "        return file['id']\n",
        "    except Exception as e:\n",
        "        return \"\"\n",
        "\n",
        "def getDriveMetadata(_id, metadata_key):\n",
        "    _metadata = service.files().get(fileId=_id, fields=metadata_key).execute()\n",
        "    metadata_value = _metadata.get(metadata_key)\n",
        "    return metadata_value\n",
        "\n",
        "# Function to create a folder in your Drive\n",
        "def create_drive_folder(name, parent_id=None):\n",
        "    folder_metadata = {\n",
        "        'name': name,\n",
        "        'mimeType': 'application/vnd.google-apps.folder',\n",
        "        'parents': [parent_id] if parent_id else [\"root\"]\n",
        "    }\n",
        "    folder = service.files().create(body=folder_metadata, fields='id').execute()\n",
        "    return folder.get('id')\n",
        "\n",
        "# Function to copy a drive file\n",
        "def transfer_drive_file(file_id, name=\"\", parent_id=None):\n",
        "    if not name:\n",
        "        name = getDriveMetadata(file_id, 'name')\n",
        "    copied_file_metadata = {\n",
        "        'name': name,\n",
        "        'parents': [parent_id] if parent_id else [\"root\"]\n",
        "    }\n",
        "    copied_file = service.files().copy(fileId=file_id, body=copied_file_metadata).execute()\n",
        "    # return name, copied_file.get('id')\n",
        "    return name\n",
        "\n",
        "# Function to recursively copy a folder\n",
        "def transfer_drive_folder(folder_id, parent_id=None):\n",
        "    # Get the folder metadata\n",
        "    folder_name = getDriveMetadata(folder_id, 'name')\n",
        "\n",
        "    # Create the folder in your Drive\n",
        "    new_folder_id = create_drive_folder(folder_name, parent_id)\n",
        "\n",
        "    # List all items in the folder\n",
        "    results = service.files().list(\n",
        "        q=f\"'{folder_id}' in parents\",\n",
        "        fields=\"files(id, name, mimeType)\"\n",
        "    ).execute()\n",
        "\n",
        "    items = results.get('files', [])\n",
        "\n",
        "    for item in items:\n",
        "        if item['mimeType'] == 'application/vnd.google-apps.folder':\n",
        "            # Recursively copy subfolder\n",
        "            transfer_drive_folder(item['id'], new_folder_id)\n",
        "        else:\n",
        "            # Copy individual file\n",
        "            transfer_drive_file(item['id'], item['name'], new_folder_id)\n",
        "\n",
        "    print(f\"Copied folder '{folder_name}' to your Drive (ID: {new_folder_id})\")\n",
        "\n",
        "\n",
        "def downloadFromPublicDrive(Drive_URLs):\n",
        "    colab_root = \"/content/\"\n",
        "    drive_root = \"/content/drive/MyDrive/\"\n",
        "    file_folder_name = \"\"\n",
        "    file_folder_path = \"\"\n",
        "\n",
        "    Drive_URLs_List = strToList(Drive_URLs)\n",
        "    for url in Drive_URLs_List:\n",
        "        public_drive_id = extractPublicDriveID(url)\n",
        "        if \"file/d/\" in url:\n",
        "            # Start copying the folder\n",
        "            try:\n",
        "                file_folder_name = transfer_drive_file(public_drive_id)\n",
        "                file_folder_path = drive_root + file_folder_name\n",
        "            except HttpError as error:\n",
        "                print(f\"Drive error occurred: {error}\")\n",
        "        elif \"folders/\" in url:\n",
        "            # Start copying the folder\n",
        "            try:\n",
        "                transfer_drive_folder(public_drive_id)\n",
        "                file_folder_name = getDriveMetadata(public_drive_id, 'name')\n",
        "                file_folder_path = drive_root + file_folder_name\n",
        "            except HttpError as error:\n",
        "                print(f\"Drive error occurred: {error}\")\n",
        "\n",
        "        print(f\"Drive Transfer Successfull: {file_folder_name}\")\n",
        "\n",
        "\n",
        "downloadFromPublicDrive(public_drive_urls)\n",
        "\n",
        "\n",
        "# _. _. _.  _. _. _.  _. _. _.  _. _. _.  _. _. _.  _. _. _."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sAMgxy_jzpre"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title dex2c Encrypter\n",
        "\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "root = \"/content\"\n",
        "ndk_path = root + \"/android-ndk-r27c\"\n",
        "dex2c_path = root + \"/dex2c\"\n",
        "dex2c_conf_filepath = f'{dex2c_path}/dcc.cfg'\n",
        "filter_filepath = f'{dex2c_path}/filter.txt'\n",
        "\n",
        "def strToList(listStr, separator):\n",
        "    listStr = ' '.join(listStr.split()) # Remove extra spaces from String\n",
        "    myList = [_.strip() for _ in listStr.split(separator)]\n",
        "    myList = [_ for _ in myList if _ and _.strip()] # Remove empty items from list\n",
        "    return myList\n",
        "\n",
        "def add_suffix_to_file(file_path, suffix=\"_Suffix\"):\n",
        "    parent_dir_path, file_name = os.path.split(file_path)\n",
        "    name, ext = os.path.splitext(file_name)\n",
        "    new_file_name = f\"{name}{suffix}{ext}\"\n",
        "    new_file_path = os.path.join(parent_dir_path, new_file_name)\n",
        "    return new_file_path\n",
        "\n",
        "def update_file(file_path, text):\n",
        "    with open(file_path, 'w') as file:\n",
        "        file.write(text)\n",
        "\n",
        "if not os.path.exists(ndk_path):\n",
        "    !wget https://dl.google.com/android/repository/android-ndk-r27c-linux.zip --no-verbose --show-progress -N\n",
        "    !7z x \"android-ndk-r27c-linux.zip\"\n",
        "\n",
        "if not os.path.exists(dex2c_path):\n",
        "    !git clone https://github.com/codehasan/dex2c && cd \"{dex2c_path}\" && pip install wget && pip install tqdm && wget -O tools/apktool.jar https://bitbucket.org/iBotPeaches/apktool/downloads/apktool_2.10.0.jar && pip3 install -r requirements.txt && sudo apt-get install openjdk-17-jdk zipalign\n",
        "\n",
        "clear_output()\n",
        "\n",
        "Input_Apk = \"https://mixologystreambot-6bb897237317.herokuapp.com/36481/Via+Browser+v6.2.0+%28Mod%29.apk?hash=AgADPh\"  #@param {type: \"string\"}\n",
        "#Input_Apk = \"/content/sample.apk\"  #@param {type: \"string\"}\n",
        "Ouput_Apk = \"\"  #@param {type: \"string\"}\n",
        "#@markdown ***Rule#1 | Rule#2 | Rule#3 so on. ***\n",
        "Filter_Rules = \"mark/via/.*;.*\"  #@param {type: \"string\"}\n",
        "#Filter_Rules = \".* , com.* \"  #@param {type: \"string\"}\n",
        "Filter_Rules = '\\n'.join(strToList(Filter_Rules, \"|\"))\n",
        "# mark/via/.*;.*\n",
        "\n",
        "dex2c_conf = f'''{{\n",
        "    \"apktool\": \"tools/apktool.jar\",\n",
        "    \"ndk_dir\": \"{ndk_path}\",\n",
        "    \"signature\": {{\n",
        "        \"keystore_path\": \"keystore/debug.keystore\",\n",
        "        \"alias\": \"androiddebugkey\",\n",
        "        \"keystore_pass\": \"android\",\n",
        "        \"store_pass\": \"android\",\n",
        "        \"v1_enabled\": true,\n",
        "        \"v2_enabled\": true,\n",
        "        \"v3_enabled\": true\n",
        "    }}\n",
        "}}'''\n",
        "update_file(dex2c_conf_filepath, dex2c_conf)\n",
        "\n",
        "filter = f'''\n",
        "# Rules are made using regex patterns\n",
        "\n",
        "# Protect all methods in all classes\n",
        "# Not recommended for real world applications.\n",
        "{Filter_Rules}\n",
        "'''\n",
        "update_file(filter_filepath, filter)\n",
        "\n",
        "import wget\n",
        "if Input_Apk.startswith(('http://', 'https://')):\n",
        "    Input_Apk = wget.download(Input_Apk)\n",
        "Input_Apk = os.path.abspath(Input_Apk)\n",
        "\n",
        "if not Ouput_Apk:\n",
        "    Ouput_Apk = add_suffix_to_file(Input_Apk, '_dex2c')\n",
        "Ouput_Apk = os.path.abspath(Ouput_Apk)\n",
        "\n",
        "if os.path.exists(Input_Apk):\n",
        "    !cat \"{dex2c_conf_filepath}\" && cat \"{filter_filepath}\"\n",
        "    !cd dex2c && python3 dcc.py -a \"{Input_Apk}\" -o \"{Ouput_Apk}\"\n",
        "    print(\"Input\")\n",
        "    !du -BM \"{Input_Apk}\"\n",
        "    print(\"Output\")\n",
        "    !du -BM \"{Ouput_Apk}\"\n",
        "    print(\"\\a\")\n",
        "else:\n",
        "    print(f\"Input Apk not found: {Input_Apk}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8AmUKfvVNOT-"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title APK Downloader\n",
        "\n",
        "!pip install PyAPKDownloader\n",
        "\n",
        "App_Package = \"https://play.google.com/store/apps/details?id=mark.via.gp\"  #@param {type: \"string\"}\n",
        "App_Package = App_Package.split(\"id=\")[1]\n",
        "\n",
        "from PyAPKDownloader.aptoide import Aptoide\n",
        "Downloader = Aptoide()\n",
        "\n",
        "Downloader.download_by_package_name(package_name=App_Package, file_name=\"default\", version=\"latest\", in_background=False, limit=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7ywu1sPNh8L"
      },
      "outputs": [],
      "source": [
        "from PyAPKDownloader.apkpure import ApkPure\n",
        "Downloader = ApkPure()\n",
        "Downloader.download_by_package_name(package_name=\"com.tencent.ig\", file_name=\"default\", version=\"latest\", app_ext=\"apk\", in_background=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JutR5JV409S"
      },
      "outputs": [],
      "source": [
        "!ls -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "DMTfWUPGCPwF"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title Telegram forwarder\n",
        "\n",
        "try:\n",
        "    from pyrogram import Client, filters\n",
        "except Exception as e:\n",
        "    !pip install pyrogram tgCrypto\n",
        "\n",
        "from pyrogram import Client, filters\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Replace with your API ID, API Hash, and session name\n",
        "app = Client(\n",
        "    \"my_account\",\n",
        "    api_id=\"22737307\",  # Get from https://my.telegram.org\n",
        "    api_hash=\"a9e79cc842e36da3e3f0b3711f8b0d5e\"  # Get from https://my.telegram.org\n",
        ")\n",
        "\n",
        "# Replace with the source channel ID (from which posts will be forwarded)\n",
        "SOURCE_CHANNEL_ID = \"@reversalhub\"  # Can be a username (str) or ID (int)\n",
        "\n",
        "# Replace with your destination channel ID (your channel where posts will be forwarded)\n",
        "DESTINATION_CHANNEL_ID = \"@premiumApps000\"  # Can be a username (str) or ID (int)\n",
        "\n",
        "async def forward_all_posts():\n",
        "    async with app:\n",
        "        print(\"Fetching and forwarding posts...\")\n",
        "\n",
        "        # Fetch all messages from the source channel\n",
        "        for message in app.get_chat_history(SOURCE_CHANNEL_ID):\n",
        "            try:\n",
        "                if message.media_group_id:\n",
        "                    # Handle media groups (albums)\n",
        "                    media_group = await app.get_media_group(SOURCE_CHANNEL_ID, message.id)\n",
        "                    # Forward the entire media group to your channel\n",
        "                    await app.forward_messages(DESTINATION_CHANNEL_ID, SOURCE_CHANNEL_ID, [m.id for m in media_group])\n",
        "                    print(f\"Forwarded media group: {message.id}\")\n",
        "                else:\n",
        "                    # Handle single messages\n",
        "                    await message.forward(DESTINATION_CHANNEL_ID)\n",
        "                    print(f\"Forwarded message: {message.id}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to forward message {message.id}: {e}\")\n",
        "\n",
        "# Run the function to forward all posts\n",
        "await app.run(forward_all_posts())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -f *"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcN59Rvztzhr",
        "outputId": "53b3ed54-ce32-42d6-82ce-22272025cb6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'drive': Is a directory\n",
            "rm: cannot remove 'Party.Till.I.Die.S01.720p.AMZN.WEB-DL.DDP2.0.H.265-PrimeFix': Is a directory\n",
            "rm: cannot remove 'sample_data': Is a directory\n",
            "rm: cannot remove 'The.Roshans.S01.720p.NF.WEB-DL.AAC5.1.AV1-PrimeFix': Is a directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e\n",
        "#@title MKV Merger\n",
        "\n",
        "MKV_FILES = \"https://mixologystreambot-6bb897237317.herokuapp.com/36917/%5BToonworld4all%5D+Solo+Leveling+S02E01+720p+x265+10bit+WEB-DL+.mkv?hash=AgADeB, https://mixologystreambot-6bb897237317.herokuapp.com/36923/Secret+Level+S1+2024+E9-15+Dual+Audio+Hindi+-+English+Comple.mkv?hash=AgAD4A\"  # @param {type: \"string\"}\n",
        "#MKV_FILES = \"https://mixologystreambot-6bb897237317.herokuapp.com/36693/114b80ac782c4e8583c7016c9f83fe13.mkv?hash=AgADlA, https://mixologystreambot-6bb897237317.herokuapp.com/36695/60656c2c21894946bade447fea690315.mkv?hash=AgADlQ\"  # @param {type: \"string\"}\n",
        "OUTPUT_DIR = \"\"  #@param {type: \"string\"}\n",
        "MAX_FileSize = None  #@param {type: \"number\"}\n",
        "JUST_DOWNLOAD= False  #@param {type: \"boolean\"}\n",
        "# Delete_Extracted_Data = False  #@param {type: \"boolean\"}\n",
        "#@markdown ***Start 00:00:00 / End 00:00:10***\n",
        "# trim_start = \"\"  #@param {type: \"string\"}\n",
        "# trim_end = \"\"  #@param {type: \"string\"}\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import subprocess\n",
        "import os\n",
        "import re\n",
        "import requests\n",
        "import patoolib\n",
        "from google.colab import drive\n",
        "from zipfile import ZipFile\n",
        "import ffmpeg\n",
        "from pymediainfo import MediaInfo\n",
        "import mimetypes\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "clear_output()\n",
        "\n",
        "\n",
        "def deleteFolder(input_folder):\n",
        "    !rm -rf \"{input_folder}\"\n",
        "    print(f\"Folder Deleted: {input_folder}\")\n",
        "\n",
        "def strToList(listStr, separator=\",\"):\n",
        "    listStr = ' '.join(listStr.split()) # Remove extra spaces from String\n",
        "    myList = [_.strip() for _ in listStr.split(separator)]\n",
        "    myList = [_ for _ in myList if _ and _.strip()] # Remove empty items from list\n",
        "    showAllURLs = \"\\n\".join(f\"{i+1}. {ele}\" for i, ele in enumerate(myList))\n",
        "    print(showAllURLs)\n",
        "    return myList\n",
        "\n",
        "def extract_file_info(file_path):\n",
        "    # parent_dir_path = os.path.dirname(file_path)\n",
        "    # file_name = os.path.basename(file_path)\n",
        "    parent_dir_path, file_name = os.path.split(file_path)\n",
        "    _name, _ext = os.path.splitext(file_name)\n",
        "    return parent_dir_path,  file_name, _name, _ext[1:]\n",
        "\n",
        "def getMKVFilesList(folder_path, relative=0):\n",
        "    all_files = []\n",
        "    for root, dirs, files in os.walk(folder_path):\n",
        "        for file in files:\n",
        "            if file.endswith('.mkv'):\n",
        "                full_path = os.path.join(root, file)\n",
        "                if relative == 1:\n",
        "                    full_path = os.path.relpath(full_path, folder_path)\n",
        "                all_files.append(full_path)\n",
        "\n",
        "    all_files.sort()\n",
        "    return all_files\n",
        "\n",
        "\n",
        "def extractArchive(Archive_File, extracted_folder=''):\n",
        "    if not extracted_folder:\n",
        "        extracted_folder = os.path.splitext(Archive_File)[0]\n",
        "    if os.path.exists(extracted_folder):\n",
        "        deleteFolder(extracted_folder)\n",
        "    os.makedirs(extracted_folder, exist_ok=True)\n",
        "    print(f\"\\nExtracting archive to: {extracted_folder}\")\n",
        "    patoolib.extract_archive(Archive_File, outdir=extracted_folder)\n",
        "    print(f\"Extraction complete: {extracted_folder}\\n\")\n",
        "    return extracted_folder\n",
        "\n",
        "\n",
        "def runCommand(cmd, showLog=0):\n",
        "    if showLog == 1:\n",
        "        # Print logs in real-time, if 2nd param is 1\n",
        "        print(f\"Running command: {cmd}\")\n",
        "        process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
        "        for line in iter(process.stdout.readline, b''):\n",
        "            print(line.decode(\"utf-8\"), end=\"\")\n",
        "\n",
        "        process.stdout.close()\n",
        "        process.wait()\n",
        "    else:\n",
        "        process = subprocess.run(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "    return process.returncode\n",
        "\n",
        "\n",
        "def getResponseFileName(url):\n",
        "    # Define the maximum filename length (commonly 255 characters)\n",
        "    MAX_FILENAME_LENGTH = 255\n",
        "\n",
        "    # Get the response from the URL\n",
        "    response = requests.get(url, stream=True)\n",
        "\n",
        "    # Extract the filename from the Content-Disposition header\n",
        "    filename = response.headers.get('content-disposition', '')\n",
        "    if 'filename=' in filename:\n",
        "        filename = filename.split(\"filename=\")[-1].strip('\"')\n",
        "    else:\n",
        "        return \"\"\n",
        "\n",
        "    # Define a regex pattern to match unsuitable characters for filenames\n",
        "    invalid_chars = r'[<>:\"/\\\\|?*\\']'\n",
        "\n",
        "    # Replace unsuitable characters with a hyphen\n",
        "    valid_filename = re.sub(invalid_chars, '-', filename)\n",
        "\n",
        "    # Truncate the filename if it exceeds the maximum length\n",
        "    if len(valid_filename) > MAX_FILENAME_LENGTH:\n",
        "        # Preserve the file extension if present\n",
        "        if '.' in valid_filename:\n",
        "            name, extension = valid_filename.rsplit('.', 1)\n",
        "            truncated_name = name[:MAX_FILENAME_LENGTH - len(extension) - 1]  # Reserve space for the dot\n",
        "            valid_filename = f\"{truncated_name}.{extension}\"\n",
        "        else:\n",
        "            valid_filename = valid_filename[:MAX_FILENAME_LENGTH]\n",
        "\n",
        "    return valid_filename\n",
        "\n",
        "\n",
        "def Aria2Downloader(url, output_file=''):\n",
        "    if not url.startswith(\"http\"):\n",
        "        print(f\"Invalid URL: {url}\")\n",
        "    _responseFileName = getResponseFileName(url)\n",
        "    if _responseFileName:\n",
        "        if not output_file:\n",
        "            output_file = _responseFileName\n",
        "        if os.path.exists(output_file):\n",
        "            print(f\"Download File Already Exists: {output_file}\")\n",
        "            return output_file\n",
        "        else:\n",
        "            \"\"\"Download a file using Aria2.\"\"\"\n",
        "            print(f\"Downloading file: {url}\")\n",
        "            command = f\"aria2c -x 16 -s 16 -o \\\"{output_file}\\\" {url}\"\n",
        "            status_code = runCommand(command, 1)\n",
        "            if status_code == 0:\n",
        "                print(f\"\\nDownload Successfull: {output_file}\\n\")\n",
        "                return output_file\n",
        "            else:\n",
        "                print(f\"Download Error Status code({status_code}): {url}\")\n",
        "    else:\n",
        "        print(f\"Download Error Response FileName: {url}\")\n",
        "    return url\n",
        "\n",
        "\n",
        "def mergeMKVs(video_paths, output_dir, max_size_gb):\n",
        "    if len(video_paths) < 2:\n",
        "        print(video_paths, f\" ==> Can't Merge {len(video_paths)} video\")\n",
        "        return video_paths\n",
        "\n",
        "    # Ensure the output directory exists\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Function to get track IDs using ffmpeg probe\n",
        "    def get_track_ids(file):\n",
        "        probe = ffmpeg.probe(file)\n",
        "        return {stream['index'] for stream in probe['streams']}\n",
        "\n",
        "    # Get all track IDs across files\n",
        "    all_track_ids = set.union(*[get_track_ids(file) for file in video_paths])\n",
        "\n",
        "    # Find files with missing track IDs\n",
        "    files_to_exclude = []\n",
        "    valid_files = []\n",
        "\n",
        "    for file in video_paths:\n",
        "        file_track_ids = get_track_ids(file)\n",
        "        if all_track_ids.issubset(file_track_ids):\n",
        "            valid_files.append(file)\n",
        "        else:\n",
        "            files_to_exclude.append(file)\n",
        "\n",
        "    # If no valid files are left, exit\n",
        "    if not valid_files:\n",
        "        print(\"No valid files to merge. All files have missing track IDs.\")\n",
        "        return files_to_exclude\n",
        "\n",
        "    # Base output file path\n",
        "    base_output_path = os.path.join(output_dir, extract_file_info(valid_files[0])[2] + \"_merged\")\n",
        "\n",
        "    # Convert max_size_gb to bytes (mkvmerge uses bytes for splitting)\n",
        "    max_size_bytes = max_size_gb * 1024 * 1024 * 1024\n",
        "\n",
        "    command = [\n",
        "        \"mkvmerge\",\n",
        "        \"-o\", f\"{base_output_path}.mkv\",\n",
        "        \"--split\", f\"{max_size_bytes}\",\n",
        "    ]\n",
        "\n",
        "    # Append valid videos sequentially\n",
        "    for i, video_path in enumerate(valid_files):\n",
        "        if i == 0:\n",
        "            command.append(video_path)  # First video\n",
        "        else:\n",
        "            command.extend([\"+\", video_path])  # Append subsequent videos\n",
        "\n",
        "    # Run the mkvmerge command\n",
        "    command_str = ' '.join(command)\n",
        "    runCommand(command_str, 1)\n",
        "\n",
        "    # Display files that were not merged\n",
        "    if files_to_exclude:\n",
        "        print(\"The following files were not merged due to missing track IDs:\")\n",
        "        for file in files_to_exclude:\n",
        "            print(f\"- {file}\")\n",
        "    else:\n",
        "        print(\"All files were merged successfully.\")\n",
        "\n",
        "    return files_to_exclude\n",
        "\n",
        "\n",
        "def main(filesListStr, output_dir=''):\n",
        "    Files_List = strToList(filesListStr, \",\")\n",
        "    _File = Files_List[0]\n",
        "\n",
        "    if len(Files_List) == 0 or (len(Files_List) == 1 and os.path.exists(_File) and _File.endswith('.mkv')):\n",
        "        print(Files_List, \" ==> Give At Least 2 files for Merging\")\n",
        "        exit()\n",
        "\n",
        "    if len(Files_List) == 1:\n",
        "        _File = Files_List[0]\n",
        "        if _File.startswith('http'):\n",
        "            _File = Aria2Downloader(_File)\n",
        "        if os.path.exists(_File):\n",
        "            if patoolib.is_archive(_File):\n",
        "                _Folder = extractArchive(_File)\n",
        "                Files_List = getMKVFilesList(_Folder)\n",
        "            elif os.path.isdir(_File):\n",
        "                Files_List = getMKVFilesList(_File)\n",
        "\n",
        "    valid_Files_List = []\n",
        "    if len(Files_List) > 1:\n",
        "        for i, valid_File in enumerate(Files_List):\n",
        "            if valid_File.startswith('http'):\n",
        "                valid_File = Aria2Downloader(valid_File)\n",
        "            if os.path.exists(valid_File):\n",
        "                if valid_File.endswith('.mkv'):\n",
        "                    valid_File = os.path.abspath(valid_File)\n",
        "                    valid_Files_List.append(valid_File)\n",
        "                else:\n",
        "                    print(\"File Exists but Unsupported File Format: \", valid_File)\n",
        "            else:\n",
        "                print(f\"Error FILES {i+1}: {valid_File}\")\n",
        "                exit()\n",
        "        print(\"Valid Files are:\\n\", \"\\n\".join(valid_Files_List))\n",
        "\n",
        "    if len(valid_Files_List) > 1:\n",
        "        if JUST_DOWNLOAD:\n",
        "            exit()\n",
        "        if not output_dir:\n",
        "            output_dir = '/content/drive/MyDrive'\n",
        "        mergeMKVs(valid_Files_List, output_dir)\n",
        "\n",
        "main(MKV_FILES, OUTPUT_DIR, MAX_FileSize)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "P8PqgFx7Jkge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pymediainfo import MediaInfo\n",
        "\n",
        "def get_track_info(file_path):\n",
        "    \"\"\"\n",
        "    Fetches and prints track details (ID, Type, Language, Title) using pymediainfo.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the media file.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        media_info = MediaInfo.parse(file_path)\n",
        "        for track in media_info.tracks:\n",
        "            if track.track_type in [\"Video\", \"Audio\", \"Text\"]:  # Only show relevant tracks\n",
        "                track_id = track.track_id or \"Unknown\"\n",
        "                track_type = track.track_type or \"Unknown\"\n",
        "                language = track.language or \"Unknown\"\n",
        "                title = track.title or \"Untitled\"\n",
        "\n",
        "                print(f\"ID: {track_id} | Type: {track_type} | Language: {language} | Title: {title}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred: {e}\")\n",
        "\n",
        "#\n",
        "# Example usage\n",
        "Video = \"/content/The.Roshans.S01.720p.NF.WEB-DL.AAC5.1.AV1-PrimeFix/The.Roshans.S01E02.720p.NF.WEB-DL.AAC5.1.AV1-PrimeFix.mkv\"  #@param {type: \"string\"}\n",
        "get_track_info(Video)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijsl9uE-vtYy",
        "outputId": "f0a5062b-bb76-4831-e8fb-b2e6852ab97a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID: 1 | Type: Video | Language: Unknown | Title: Untitled\n",
            "ID: 2 | Type: Audio | Language: hi | Title: Untitled\n",
            "ID: 3 | Type: Text | Language: en | Title: Untitled\n",
            "ID: 4 | Type: Text | Language: en | Title: Untitled\n",
            "ID: 5 | Type: Text | Language: en | Title: SDH\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1hxWtFIxErAIuElM-8z9T7PBf6VZz0eVg",
      "authorship_tag": "ABX9TyPanaC4L3emA4eC8KngchaX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}